import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
import io
import json
import re
import chromadb
import pickle
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np

load_dotenv()

st.set_page_config(page_title="Gemini Chat App", page_icon="ğŸ¤–")

def check_password():
    """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ã‚’è¡Œã†é–¢æ•°"""

    def password_entered():
        """ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚ŒãŸã¨ãã®å‡¦ç†"""
        auth_user = os.getenv("AUTH_USERNAME")
        auth_pass = os.getenv("AUTH_PASSWORD")

        if (st.session_state["username"] == auth_user and
            st.session_state["password"] == auth_pass):
            st.session_state["password_correct"] = True
            del st.session_state["password"]
            del st.session_state["username"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False

    if not st.session_state["password_correct"]:
        st.title("ğŸ” ãƒ­ã‚°ã‚¤ãƒ³")
        st.write("ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã«ã¯ãƒ­ã‚°ã‚¤ãƒ³ãŒå¿…è¦ã§ã™")

        with st.form("login_form"):
            st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å", key="username")
            st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", key="password")
            st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³", on_click=password_entered)

        if "password_correct" in st.session_state and not st.session_state["password_correct"]:
            st.error("ğŸ˜• ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“")

        st.markdown("---")
        st.caption("ç®¡ç†è€…ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã¦ãã ã•ã„")
        return False

    return True

def analyze_image_with_prompt(image, prompt):
    """ç”»åƒã‚’å®šå‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§åˆ†æã—ã¦JSONãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        model = st.session_state.model
        content = [image, prompt]
        response = model.generate_content(content)

        # JSONãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
        response_text = response.text

        # ```json ã‹ã‚‰ ```ã¾ã§ã®éƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r'```json\s*(.*?)\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            # {}ã§å›²ã¾ã‚ŒãŸJSONã‚’æ¢ã™
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                json_str = response_text

        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        try:
            json_data = json.loads(json_str)
            return json_data, response_text
        except json.JSONDecodeError:
            return None, response_text

    except Exception as e:
        return None, f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

def check_ngwords_in_query_strings(query_strings, threshold=0.3):
    """query_stringãƒªã‚¹ãƒˆã‚’NGãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã§ãƒã‚§ãƒƒã‚¯"""
    if not query_strings:
        return []
    
    vectorizer, collection = load_vectorizer_and_db()
    if vectorizer is None or collection is None:
        return []
    
    all_ngword_results = []
    for query in query_strings:
        if query and query.strip():
            ngword_results = search_ng_words(query.strip(), vectorizer, collection, threshold, 5)
            if ngword_results:
                all_ngword_results.append({
                    'query': query,
                    'ngwords': ngword_results
                })
    
    return all_ngword_results

def display_json_data(json_data):
    """JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆå½¢å¼ã§è¡¨ç¤ºï¼ˆæ–°ã—ã„é…åˆ—å½¢å¼ã«å¯¾å¿œï¼‰"""
    if isinstance(json_data, list):
        st.subheader("ğŸ“‹ åˆ†æçµæœ")

        for item in json_data:
            if isinstance(item, dict) and 'id' in item:
                # æ–°ã—ã„å½¢å¼ã®JSONãƒ‡ãƒ¼ã‚¿
                item_id = item.get('id', 'N/A')
                objects = item.get('object', [])
                texts = item.get('text', [])
                source = item.get('source', 'N/A')
                query_strings = item.get('query_string', [])

                # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ©ãƒ™ãƒ«ã‚’å–å¾—ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã«ä½¿ç”¨
                title_parts = []
                if objects:
                    for obj in objects:
                        if isinstance(obj, dict):
                            label = obj.get('label', '')
                            if label:
                                title_parts.append(label)

                # ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã‚‚ã‚¿ã‚¤ãƒˆãƒ«è¦ç´ ã‚’è¿½åŠ 
                if texts and len(texts) > 0:
                    title_parts.extend(texts[:2])  # æœ€åˆã®2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 

                title = ' / '.join(title_parts) if title_parts else f"ãƒ–ãƒ­ãƒƒã‚¯ {item_id}"

                # NGãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œ
                ngword_results = check_ngwords_in_query_strings(query_strings)
                has_ngwords = len(ngword_results) > 0
                
                # NGãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯è­¦å‘Šã‚¢ã‚¤ã‚³ãƒ³ã‚’è¿½åŠ 
                warning_icon = "âš ï¸ " if has_ngwords else ""

                with st.expander(f"ğŸ” {warning_icon}{title} (ID: {item_id})", expanded=True):
                    col1, col2 = st.columns([1, 1])

                    with col1:
                        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
                        if objects:
                            st.write("**ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ:**")
                            for obj in objects:
                                if isinstance(obj, dict):
                                    label = obj.get('label', 'N/A')
                                    category = obj.get('category', 'N/A')

                                    # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸã‚¢ã‚¤ã‚³ãƒ³
                                    category_icons = {
                                        'äººã®é¡”': 'ğŸ‘¤',
                                        'åŒ–ç²§å“å®¹å™¨': 'ğŸ§´',
                                        'ãã®ä»–': 'ğŸ“¦'
                                    }
                                    icon = category_icons.get(category, 'ğŸ“¦')

                                    st.write(f"  {icon} **{label}** ({category})")
                        else:
                            st.write("**ğŸ¯ æ¤œå‡ºã•ã‚ŒãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ:** ãªã—")

                        # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
                        if texts:
                            st.write("**ğŸ“ æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ:**")
                            for idx, text in enumerate(texts, 1):
                                st.write(f"  {idx}. {text}")
                        else:
                            st.write("**ğŸ“ æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ:** ãªã—")

                    with col2:
                        # ã‚½ãƒ¼ã‚¹æƒ…å ±
                        st.write(f"**ğŸ“ ã‚½ãƒ¼ã‚¹:** {source}")

                        # ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—
                        if query_strings:
                            st.write("**ğŸ” ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—:**")
                            for idx, query in enumerate(query_strings, 1):
                                st.code(query, language="text")
                        else:
                            st.write("**ğŸ” ã‚¯ã‚¨ãƒªæ–‡å­—åˆ—:** ãªã—")
                    
                    # NGãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœã®è¡¨ç¤º
                    if has_ngwords:
                        st.markdown("---")
                        st.write("**ğŸš« NGãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœ:**")
                        
                        for ngword_result in ngword_results:
                            query = ngword_result['query']
                            ngwords = ngword_result['ngwords']
                            
                            st.write(f"**ã‚¯ã‚¨ãƒª:** `{query}`")
                            
                            # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¥ã®è‰²åˆ†ã‘
                            risk_colors = {
                                'high': 'ğŸ”´',
                                'mid': 'ğŸŸ¡', 
                                'low': 'ğŸŸ¢'
                            }
                            
                            for ngword in ngwords[:3]:  # ä¸Šä½3ä»¶ã®ã¿è¡¨ç¤º
                                risk_icon = risk_colors.get(ngword['risk_level'], 'âšª')
                                st.warning(f"{risk_icon} **{ngword['ng_word']}** (é¡ä¼¼åº¦: {ngword['similarity']:.3f}) â†’ {ngword['replacement']}")
                            
                            if len(ngwords) > 3:
                                st.caption(f"...ä»– {len(ngwords) - 3} ä»¶ã®NGãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                    else:
                        st.markdown("---")
                        st.success("âœ… NGãƒ¯ãƒ¼ãƒ‰ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            else:
                # å¾“æ¥ã®å½¢å¼ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ï¼‰
                with st.expander(f"{item.get('title', item.get('name', f'ã‚¢ã‚¤ãƒ†ãƒ '))}", expanded=True):
                    for k, v in item.items():
                        if k not in ['title', 'name']:
                            st.write(f"**{k}**: {v}")

    elif isinstance(json_data, dict):
        # è¾æ›¸å½¢å¼ã®å ´åˆï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰
        for key, value in json_data.items():
            if isinstance(value, list):
                st.subheader(f"ğŸ“‹ {key}")
                for idx, item in enumerate(value, 1):
                    if isinstance(item, dict):
                        with st.expander(f"{idx}. {item.get('title', item.get('name', f'ã‚¢ã‚¤ãƒ†ãƒ {idx}'))}", expanded=True):
                            for k, v in item.items():
                                if k not in ['title', 'name']:
                                    st.write(f"**{k}**: {v}")
                    else:
                        st.write(f"{idx}. {item}")
            elif isinstance(value, dict):
                st.subheader(f"ğŸ“‹ {key}")
                for k, v in value.items():
                    st.write(f"**{k}**: {v}")
            else:
                st.write(f"**{key}**: {value}")

if not check_password():
    st.stop()

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

st.title("ğŸ¤– Gemini Multi-Tool Application")
st.write("ç”»åƒåˆ†æãƒ»ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æãƒ»æ–‡æ›¸å‡¦ç†ãªã©ã®å¤šæ©Ÿèƒ½ãƒ„ãƒ¼ãƒ«")

if "messages" not in st.session_state:
    st.session_state.messages = []

if "model" not in st.session_state:
    st.session_state.model = genai.GenerativeModel("gemini-2.5-flash")

if "analysis_results" not in st.session_state:
    st.session_state.analysis_results = []

if "file_analysis_results" not in st.session_state:
    st.session_state.file_analysis_results = []

# NGãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨ã®ã‚¯ãƒ©ã‚¹ã¨é–¢æ•°
class SimpleJapaneseVectorizer:
    """ã‚·ãƒ³ãƒ—ãƒ«ãªæ—¥æœ¬èªãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.vectorizer = TfidfVectorizer(
            analyzer='char',
            ngram_range=(2, 4),
            max_features=5000,
            lowercase=False,
            token_pattern=None
        )
        self.fitted = False

    def fit_transform(self, texts):
        vectors = self.vectorizer.fit_transform(texts)
        self.fitted = True
        return vectors.toarray()

    def transform(self, texts):
        if not self.fitted:
            raise ValueError("Vectorizer has not been fitted yet")
        vectors = self.vectorizer.transform(texts)
        return vectors.toarray()

@st.cache_resource
def load_vectorizer_and_db():
    """ãƒ™ã‚¯ãƒˆãƒ©ã‚¤ã‚¶ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ä»˜ãï¼‰"""
    try:
        with open("tfidf_vectorizer.pkl", "rb") as f:
            vectorizer = pickle.load(f)

        chroma_client = chromadb.PersistentClient(path="./chroma_db")
        collection = chroma_client.get_collection("ng_words_simple")

        return vectorizer, collection
    except Exception as e:
        return None, None

def search_ng_words(query, vectorizer, collection, threshold=0.3, max_results=10):
    """NGãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢"""
    try:
        query_embedding = vectorizer.transform([query])

        results = collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=max_results
        )

        search_results = []
        for i, (doc, metadata, distance) in enumerate(zip(
            results['documents'][0],
            results['metadatas'][0],
            results['distances'][0]
        )):
            similarity = 1 - distance

            if similarity >= threshold:
                result = {
                    'ng_word': metadata['ng_word'],
                    'replacement': metadata['replacement'],
                    'reason': metadata['reason'],
                    'risk_level': metadata['risk_level'],
                    'similarity': similarity,
                    'distance': distance
                }
                search_results.append(result)

        return search_results

    except Exception as e:
        return []

def display_ngword_search_results(results, query):
    """NGãƒ¯ãƒ¼ãƒ‰æ¤œç´¢çµæœã‚’è¡¨ç¤º"""
    if not results:
        st.warning("è©²å½“ã™ã‚‹NGãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.info("ğŸ’¡ é¡ä¼¼åº¦ã—ãã„å€¤ã‚’ä¸‹ã’ã‚‹ã‹ã€åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
        return

    st.success(f"ğŸ¯ '{query}' ã«é¡ä¼¼ã™ã‚‹NGãƒ¯ãƒ¼ãƒ‰ã‚’ {len(results)} ä»¶ç™ºè¦‹ã—ã¾ã—ãŸ")

    risk_colors = {
        'high': 'ğŸ”´',
        'mid': 'ğŸŸ¡',
        'low': 'ğŸŸ¢'
    }

    for i, result in enumerate(results, 1):
        risk_icon = risk_colors.get(result['risk_level'], 'âšª')

        with st.expander(
            f"{risk_icon} {i}. ã€Œ{result['ng_word']}ã€ (é¡ä¼¼åº¦: {result['similarity']:.3f})",
            expanded=i<=3
        ):
            col1, col2 = st.columns([1, 1])

            with col1:
                st.write("**âŒ NGãƒ¯ãƒ¼ãƒ‰:**")
                st.code(result['ng_word'], language="text")

                st.write("**âœ… ç½®æ›å€™è£œ:**")
                st.code(result['replacement'], language="text")

            with col2:
                st.write("**ğŸ“‹ è©³ç´°æƒ…å ±:**")
                st.write(f"â€¢ **ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«:** {result['risk_level'].upper()}")
                st.write(f"â€¢ **é¡ä¼¼åº¦:** {result['similarity']:.4f}")
                st.write(f"â€¢ **è·é›¢:** {result['distance']:.4f}")

            st.write("**ğŸ” NGç†ç”±:**")
            st.info(result['reason'])

# ãƒ¡ã‚¤ãƒ³ã‚¿ãƒ–
tab1, tab2, tab3 = st.tabs(["ğŸ–¼ï¸ ç”»åƒåˆ†æ", "ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ", "ğŸš« NGãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"])

with tab1:
    st.subheader("ğŸ–¼ï¸ ç”»åƒåˆ†ææ©Ÿèƒ½")

    # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­å®š
    with st.expander("ğŸ”§ åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š", expanded=False):
        default_prompt = """ã“ã®ç”»åƒã‚’è©³ç´°ã«åˆ†æã—ã¦ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§çµæœã‚’è¿”ã—ã¦ãã ã•ã„ï¼š

ç”»åƒã‹ã‚‰ãã®ç”»åƒã®ãƒ–ãƒ­ãƒƒã‚¯ã”ã¨ã«ã€ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨æ–‡å­—åˆ—ã‚’æŠ½å‡ºã—ã€ä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
ãƒ«ãƒ¼ãƒ«:
- idã¯1ã‹ã‚‰ã®é€£ç•ª
- objectã¯å­˜åœ¨ã™ã‚‹å ´åˆã®ã¿å‡ºåŠ›
- objectã¯ { "label": "<15æ–‡å­—ä»¥å†…>", "category": "<äººã®é¡”/åŒ–ç²§å“å®¹å™¨/ãã®ä»–>" }
- textã¯å¿…ãšé…åˆ—
- query_stringã¯textã®è¦ç´ ã”ã¨ã«1å¯¾1ã§ç”Ÿæˆ
  - objectã‚ã‚Š â†’ "category text"
  - objectãªã— â†’ "text"
JSONå½¢å¼:
[
  {
    "id": <number>,
    "object": [ { "label": "<string>", "category": "<string>" } ],
    "text": ["<string>", "<string>"],
    "source": "<filename>",
    "query_string": ["<string>", "<string>"]
  }
]

å¿…ãšæœ‰åŠ¹ãªJSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

        analysis_prompt = st.text_area(
            "åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value=default_prompt,
            height=200
        )

    # ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "ğŸ“¸ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æé–‹å§‹",
        type=['png', 'jpg', 'jpeg', 'gif', 'webp'],
        key="main_uploader"
    )

    if uploaded_file is not None:
        # ç”»åƒè¡¨ç¤º
        st.image(uploaded_file, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", width=400)

        # åˆ†æå®Ÿè¡Œã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("---")
        st.subheader("ğŸ” åˆ†æçµæœ")

        # åˆ†æå®Ÿè¡Œ
        img_bytes = uploaded_file.read()
        img = Image.open(io.BytesIO(img_bytes))

        with st.spinner("ç”»åƒã‚’åˆ†æã—ã¦ã„ã¾ã™..."):
            json_data, raw_response = analyze_image_with_prompt(img, analysis_prompt)

        if json_data:
            st.success("âœ… åˆ†æå®Œäº†ï¼")

            # JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒªã‚¹ãƒˆè¡¨ç¤º
            display_json_data(json_data)

            # ç”Ÿãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            with st.expander("ğŸ“„ ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹", expanded=False):
                st.text(raw_response)

            # åˆ†æçµæœã‚’å±¥æ­´ã«ä¿å­˜
            from datetime import datetime
            st.session_state.analysis_results.append({
                "image": img_bytes,
                "json_data": json_data,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })

        else:
            st.error("âŒ JSONå½¢å¼ã§ã®åˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ")
            st.text("ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹:")
            st.text(raw_response)

    # åˆ†æå±¥æ­´
    if st.session_state.analysis_results:
        st.markdown("---")
        st.subheader("ğŸ“š ç”»åƒåˆ†æå±¥æ­´")

        for idx, result in enumerate(reversed(st.session_state.analysis_results[-5:]), 1):  # æœ€æ–°5ä»¶
            with st.expander(f"åˆ†æçµæœ {idx}", expanded=False):
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.image(result["image"], width=200)
                with col2:
                    display_json_data(result["json_data"])

with tab2:
    st.subheader("ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†ææ©Ÿèƒ½")
    st.write("ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã€CSVã€JSONãªã©ã‚’åˆ†æã—ã¾ã™")

    # å›ºå®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¨­å®š
    with st.expander("ğŸ”§ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š", expanded=False):
        file_default_prompt = """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’è©³ç´°ã«åˆ†æã—ã¦ã€ä»¥ä¸‹ã®è¦³ç‚¹ã§è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š

1. **ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¨®é¡ã¨æ§‹é€ **
2. **ãƒ‡ãƒ¼ã‚¿ã®å“è³ªã¨æ•´åˆæ€§**
3. **ä¸»è¦ãªç‰¹å¾´ã¨çµ±è¨ˆæƒ…å ±**
4. **æ½œåœ¨çš„ãªå•é¡Œç‚¹ã‚„æ”¹å–„ææ¡ˆ**
5. **ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã‚„æ´»ç”¨æ–¹æ³•**

åˆ†æã¯æ—¥æœ¬èªã§ã€ã‚ã‹ã‚Šã‚„ã™ãæ§‹é€ åŒ–ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

        file_analysis_prompt = st.text_area(
            "ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value=file_default_prompt,
            height=150
        )

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ†æé–‹å§‹",
        type=['txt', 'csv', 'json', 'md', 'py', 'js', 'html', 'xml'],
        key="file_uploader"
    )

    if uploaded_file is not None:
        col1, col2 = st.columns([1, 2])

        with col1:
            st.write("**ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±:**")
            st.write(f"â€¢ **åå‰:** {uploaded_file.name}")
            st.write(f"â€¢ **ã‚µã‚¤ã‚º:** {uploaded_file.size:,} bytes")
            st.write(f"â€¢ **ã‚¿ã‚¤ãƒ—:** {uploaded_file.type}")

            # ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            try:
                file_content = uploaded_file.read()
                if uploaded_file.type.startswith('text') or uploaded_file.name.endswith(('.txt', '.csv', '.json', '.md', '.py', '.js', '.html', '.xml')):
                    content_str = file_content.decode('utf-8')
                    st.write("**ğŸ“„ å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼:**")
                    st.text(content_str[:500] + ("..." if len(content_str) > 500 else ""))
                else:
                    content_str = str(file_content[:1000])
                    st.write("**ğŸ“„ ãƒã‚¤ãƒŠãƒªå†…å®¹ (ä¸€éƒ¨):**")
                    st.text(content_str[:200] + "...")
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
                content_str = ""

        with col2:
            if content_str and st.button("ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æå®Ÿè¡Œ", type="primary"):
                st.subheader("ğŸ” åˆ†æä¸­...")

                with st.spinner("Geminiã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æã—ã¦ã„ã¾ã™..."):
                    try:
                        # Geminiã«ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã¨å›ºå®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é€ä¿¡
                        full_prompt = f"{file_analysis_prompt}\n\nã€ãƒ•ã‚¡ã‚¤ãƒ«åã€‘: {uploaded_file.name}\nã€ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã€‘:\n{content_str}"

                        response = st.session_state.model.generate_content(full_prompt)
                        analysis_result = response.text

                        st.success("âœ… ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æå®Œäº†ï¼")

                        # åˆ†æçµæœã‚’è¡¨ç¤º
                        st.markdown("---")
                        st.markdown("### ğŸ“‹ åˆ†æçµæœ")
                        st.markdown(analysis_result)

                        # ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                        with st.expander("ğŸ“„ ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹", expanded=False):
                            st.text(analysis_result)

                        # åˆ†æçµæœã‚’å±¥æ­´ã«ä¿å­˜
                        from datetime import datetime
                        st.session_state.file_analysis_results.append({
                            "filename": uploaded_file.name,
                            "file_size": uploaded_file.size,
                            "file_type": uploaded_file.type,
                            "analysis_result": analysis_result,
                            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        })

                    except Exception as e:
                        st.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æå±¥æ­´
    if st.session_state.file_analysis_results:
        st.markdown("---")
        st.subheader("ğŸ“š ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æå±¥æ­´")

        for idx, result in enumerate(reversed(st.session_state.file_analysis_results[-5:]), 1):  # æœ€æ–°5ä»¶
            with st.expander(f"{result['filename']} ({result['timestamp']})", expanded=False):
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º:** {result['file_size']:,} bytes")
                st.write(f"**ãƒ•ã‚¡ã‚¤ãƒ«ã‚¿ã‚¤ãƒ—:** {result['file_type']}")
                st.markdown("**åˆ†æçµæœ:**")
                st.markdown(result['analysis_result'])

with tab3:
    st.subheader("ğŸš« NGãƒ¯ãƒ¼ãƒ‰æ¤œç´¢æ©Ÿèƒ½")
    st.write("åºƒå‘Šãƒ»ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ–‡è¨€ã®NGãƒ¯ãƒ¼ãƒ‰ã‚’ãƒ™ã‚¯ãƒˆãƒ«é¡ä¼¼æ€§ã§æ¤œå‡ºã—ã¾ã™")

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çŠ¶æ³ã®ç¢ºèª
    if not os.path.exists("./chroma_db") or not os.path.exists("tfidf_vectorizer.pkl"):
        st.error("âŒ NGãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.info("ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ã‚‚ã‚‰ã£ã¦ãã ã•ã„ã€‚")
    else:
        # æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        col1, col2 = st.columns([3, 1])

        with col1:
            query = st.text_input(
                "æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„ãƒ•ãƒ¬ãƒ¼ã‚ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
                placeholder="ä¾‹: ç¾ç™½åŠ¹æœã€ãƒ‹ã‚­ãƒ“ãŒæ²»ã‚‹ã€ã‚¢ãƒ³ãƒã‚¨ã‚¤ã‚¸ãƒ³ã‚°ã€è‚Œè’ã‚Œæ”¹å–„"
            )

        with col2:
            search_button = st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", type="primary")

        # è©³ç´°è¨­å®š
        with st.expander("âš™ï¸ æ¤œç´¢è¨­å®š", expanded=False):
            col1, col2 = st.columns(2)

            with col1:
                threshold = st.slider(
                    "é¡ä¼¼åº¦ã—ãã„å€¤",
                    min_value=0.1,
                    max_value=1.0,
                    value=0.3,
                    step=0.05,
                    help="ã“ã®å€¤ä»¥ä¸Šã®é¡ä¼¼åº¦ã‚’æŒã¤NGãƒ¯ãƒ¼ãƒ‰ã‚’è¡¨ç¤ºã—ã¾ã™"
                )

            with col2:
                max_results = st.number_input(
                    "æœ€å¤§è¡¨ç¤ºä»¶æ•°",
                    min_value=1,
                    max_value=50,
                    value=10
                )

        # æ¤œç´¢å®Ÿè¡Œ
        if (search_button or query) and query.strip():
            vectorizer, collection = load_vectorizer_and_db()

            if vectorizer is not None and collection is not None:
                with st.spinner("NGãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢ä¸­..."):
                    results = search_ng_words(query, vectorizer, collection, threshold, max_results)

                display_ngword_search_results(results, query)

                # æ¤œç´¢ã®ãƒ’ãƒ³ãƒˆ
                if not results:
                    st.info("""
                    ğŸ’¡ **æ¤œç´¢ã®ãƒ’ãƒ³ãƒˆ:**
                    - TF-IDFã¯æ–‡å­—ãƒ¬ãƒ™ãƒ«ã®é¡ä¼¼æ€§ã‚’è¦‹ã‚‹ãŸã‚ã€å®Œå…¨ä¸€è‡´ã«è¿‘ã„è¡¨ç¾ãŒã‚ˆã‚Šé«˜ã„é¡ä¼¼åº¦ã‚’ç¤ºã—ã¾ã™
                    - é¡ä¼¼åº¦ã—ãã„å€¤ã‚’ä¸‹ã’ã¦ã¿ã¦ãã ã•ã„ (æ¨å¥¨: 0.1-0.4)
                    - åŒã˜æ„å‘³ã§ã‚‚è¡¨ç¾ãŒç•°ãªã‚‹å ´åˆã¯æ¤œå‡ºã•ã‚Œã«ãã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
                    """)
            else:
                st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        # ãƒãƒƒãƒãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½
        st.markdown("---")
        st.subheader("ğŸ“ ãƒãƒƒãƒãƒã‚§ãƒƒã‚¯")
        st.write("è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€åº¦ã«ãƒã‚§ãƒƒã‚¯ã§ãã¾ã™")

        batch_text = st.text_area(
            "ãƒã‚§ãƒƒã‚¯ã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ1è¡Œ1é …ç›®ï¼‰",
            height=150,
            placeholder="ç¾ç™½åŠ¹æœæŠœç¾¤\nãƒ‹ã‚­ãƒ“ãŒæ²»ã‚‹\nã‚¢ãƒ³ãƒã‚¨ã‚¤ã‚¸ãƒ³ã‚°åŠ¹æœ\nè‚Œè’ã‚Œæ”¹å–„\nå‰¯ä½œç”¨ãªã—"
        )

        col1, col2 = st.columns(2)
        with col1:
            batch_threshold = st.slider(
                "ãƒãƒƒãƒé¡ä¼¼åº¦ã—ãã„å€¤",
                min_value=0.1,
                max_value=1.0,
                value=0.3,
                step=0.05
            )
        with col2:
            batch_max_results = st.number_input(
                "ãƒãƒƒãƒæœ€å¤§çµæœæ•°",
                min_value=1,
                max_value=20,
                value=5
            )

        if st.button("ğŸš€ ãƒãƒƒãƒãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ") and batch_text.strip():
            vectorizer, collection = load_vectorizer_and_db()
            if vectorizer is None or collection is None:
                st.error("âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                lines = [line.strip() for line in batch_text.split('\n') if line.strip()]

                results_data = []
                progress_bar = st.progress(0)

                for i, line in enumerate(lines):
                    results = search_ng_words(line, vectorizer, collection, batch_threshold, batch_max_results)

                    if results:
                        for result in results:
                            results_data.append({
                                'ãƒã‚§ãƒƒã‚¯å¯¾è±¡': line,
                                'NGãƒ¯ãƒ¼ãƒ‰': result['ng_word'],
                                'ç½®æ›å€™è£œ': result['replacement'],
                                'ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«': result['risk_level'],
                                'é¡ä¼¼åº¦': f"{result['similarity']:.3f}"
                            })
                    else:
                        results_data.append({
                            'ãƒã‚§ãƒƒã‚¯å¯¾è±¡': line,
                            'NGãƒ¯ãƒ¼ãƒ‰': '(æ¤œå‡ºãªã—)',
                            'ç½®æ›å€™è£œ': 'å•é¡Œãªã—',
                            'ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«': 'safe',
                            'é¡ä¼¼åº¦': '0.000'
                        })

                    progress_bar.progress((i + 1) / len(lines))

                if results_data:
                    st.write(f"### ğŸ“Š ãƒãƒƒãƒãƒã‚§ãƒƒã‚¯çµæœ: {len(lines)} é …ç›®ã‚’æ¤œæŸ»")

                    df = pd.DataFrame(results_data)

                    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¥ã®ã‚«ã‚¦ãƒ³ãƒˆ
                    risk_counts = df[df['ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«'] != 'safe']['ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«'].value_counts()
                    if not risk_counts.empty:
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("ğŸ”´ é«˜ãƒªã‚¹ã‚¯", risk_counts.get('high', 0))
                        with col2:
                            st.metric("ğŸŸ¡ ä¸­ãƒªã‚¹ã‚¯", risk_counts.get('mid', 0))
                        with col3:
                            st.metric("ğŸŸ¢ ä½ãƒªã‚¹ã‚¯", risk_counts.get('low', 0))
                        with col4:
                            st.metric("âœ… å®‰å…¨", len(df[df['ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«'] == 'safe']))

                    # çµæœã®è¡¨ç¤º
                    st.dataframe(df, use_container_width=True)

                    # CSVå‡ºåŠ›æ©Ÿèƒ½
                    from datetime import datetime
                    csv = df.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ“¥ çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv,
                        file_name=f"ngword_check_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )

with st.sidebar:
    st.header("è¨­å®š")

    if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", type="secondary"):
        st.session_state["password_correct"] = False
        st.rerun()

    st.markdown("---")

    model_name = st.selectbox(
        "ãƒ¢ãƒ‡ãƒ«é¸æŠ",
        [
            "gemini-2.5-flash",
            "gemini-2.5-pro",
            "gemini-2.5-flash-lite",
            "gemini-2.0-flash",
            "gemini-1.5-flash",
            "gemini-1.5-flash-8b"
        ],
        index=0
    )

    if st.button("ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›´"):
        st.session_state.model = genai.GenerativeModel(model_name)
        st.success(f"ãƒ¢ãƒ‡ãƒ«ã‚’ {model_name} ã«å¤‰æ›´ã—ã¾ã—ãŸ")

    if st.button("åˆ†æå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.analysis_results = []
        st.session_state.file_analysis_results = []
        st.rerun()

    st.markdown("---")
    st.markdown("### ä½¿ã„æ–¹")
    st.markdown("""
    **ğŸ–¼ï¸ ç”»åƒåˆ†æ:**
    1. åˆ†æç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®š
    2. ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    3. JSONå½¢å¼ã§è‡ªå‹•åˆ†æ

    **ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ:**
    1. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¨­å®šï¼ˆã‚«ã‚¹ã‚¿ãƒ å¯ï¼‰
    2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    3. Geminiã«ã‚ˆã‚‹è©³ç´°åˆ†æ

    ### å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
    **ç”»åƒ**: PNG, JPG, JPEG, GIF, WebP
    **ãƒ•ã‚¡ã‚¤ãƒ«**: TXT, CSV, JSON, MD, PY, JS, HTML, XML
    """)

    st.markdown("---")
    st.caption("ğŸ’¡ AIã«ã‚ˆã‚‹ãƒãƒ«ãƒãƒ¡ãƒ‡ã‚£ã‚¢åˆ†æãƒ„ãƒ¼ãƒ«")